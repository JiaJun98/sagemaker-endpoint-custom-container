{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Iris model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://xgboost.readthedocs.io/en/stable/get_started.html\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read data\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)\n",
    "\n",
    "# Create model instance\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score on test data predictions\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy: {}%\".format(round(accuracy * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "pickle_name = 'model.pkl'\n",
    "tar_name = 'model.tar.gz'\n",
    "\n",
    "try:\n",
    "    # Save the model as a pickled file\n",
    "    with open(pickle_name, 'wb') as pickle_file:\n",
    "        pickle.dump(model, pickle_file)\n",
    "    \n",
    "    # Create a tar.gz file\n",
    "    with tarfile.open(tar_name, 'w:gz') as tar:\n",
    "        # Add the model file to the tar.gz file\n",
    "        tar.add(pickle_name)\n",
    "    \n",
    "    print(f\"Model saved successfully as '{pickle_name}' and archived as '{tar_name}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Set up Boto3 client for S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the file path of the file to upload\n",
    "file_path = tar_name\n",
    "\n",
    "# Define the name of the bucket where you want to upload the file\n",
    "bucket_name = 'mlbucket13'\n",
    "\n",
    "# Define the key (i.e., object name) under which you want to store the file in the bucket\n",
    "key = f'mastersagemaker/part2/{tar_name}'\n",
    "\n",
    "# Upload the file to S3\n",
    "try:\n",
    "    s3.upload_file(file_path, bucket_name, key)\n",
    "    print(\"File uploaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
